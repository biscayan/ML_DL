# Chapter 1. 서론

## 1.2. 머신러닝의 기본 용어
- 속성 (attribute) 또는 특성 (feature) : 사물이나 대상의 특정 부분 혹은 성질을 반영하는 것  
- 학습 : 데이터를 통해 모델을 만들어가는 과정  
- 학습은 데이터를 통해 가설을 세우고 잠재되어 있는 규칙을 찾아내는 것을 목표로 한다.  
- 회귀 : 예측하려는 값이 0.95, 0.73처럼 정량적으로 나타낼 수 있는 연속값일 경우의 문제  
- 검증 : 학습을 통해 모델을 만든 후, 해당 모델을 활용하여 예측하는 과정  
- 일반화 : 학습된 모델이 새로운 데이터에 적용되고 좋은 퍼포먼스를 내는 것  
- 일반화 능력이 있는 모델은 비록 무한한 샘플 공간의 일부 데이터를 활용해 훈련했다 하더라도 전체적인 샘플 공간의 특성을 충분히 반영하리라 기대할 수 있지만 일반화 능력이 없는 모델이라면 새로운 데이터 샘플에 적용하기 힘들다.  

## 1.3. 가설 공간
- 귀납 : '특수'에서 '일반'으로 일반화하는 과정  
- 연역 : '일반'에서 '특수'로 특화하는 과정  
- 귀납 학습은 넓은 의미에서 샘플을 통해 배우는 것이고, 좁은 의미에서는 훈련 데이터에서 개념을 배우는 것이다.  

## 1.4. 귀납적 편향
구체적인 학습 알고리즘은 반드시 하나의 모델을 생성해 내야 하는데, 이때 학습 알고리즘 본연의 '편향'이 중요하게 작용한다. 머신러닝 알고리즘이 학습 과정에서 특정한 유형의 가설에 대한 편향을 귀납적 편향 혹은 편향이라고 부른다.  
모든 유효한 머신러닝 알고리즘은 귀납적 편향을 가지고 있다. 만약 편향을 가지고 있지 않다면 학습 알고리즘이 생성한 모델은 매번 예측할 때마다 효과가 같아 보이는 비슷한 가설들 사이에서 혼란에 빠지며 확실한 학습 결과를 생성해 낼 수 없다. 따라서 학습 알고리즘은 반드시 어떤 편향을 가지고 있어야만 정확하다고 여겨질 수 있는 모델을 생성할 수 있다.  

## 1.5. 발전 과정
- 1950년대부터 1970년대 초까지 인공지능 연구는 '추론기'에 머물러 있었다. 당시에 사람들은 기계에 논리적인 추론 능력을 더하면 지능을 얻게 될 것이라고 생각했다.  
- 1970년대 중반부터 기계가 지능을 가지려면 기계에도 지식이 있어야 한다고 주장하면서 인공지능 연구는 '지식기'에 진입하게 된다. 인간이 지식을 종합해 컴퓨터에 전달하는 것이 어려운 일이라는 것을 인지하게 되고, 결국 어떤 학자들은 기계가 스스로 지식을 습득하는 방법을 고안하기 시작했다.  
- 1980년대는 머신러닝이 하나의 독립적인 과학 영역으로 분리된 시기이며, 각종 머신러닝 기술이 발전하며 자리를 잡기 시작한 시기이다. 머신러닝 연구를 '샘플을 통한 학습', '문제 해결과 계획을 통한 학습', '명령을 통한 학습' 등으로 분류했으며, '샘플을 통한 학습'이 연구와 응용이 가장 많이 진행되었다. '샘플을 통한 학습'의 주류는 의사결정 트리와 논리에 기반을 둔 학습을 포함하는 기호주의 학습이었다. 
- 1990년대 중반 이전에 '샘플로부터의 학습'의 다른 주류 기술 중 하나는 신경망에 기반을 둔 연결주의 학습이었다. 명확한 개념표현을 생성해 내는 것과 다르게, 연결주의 학습은 블랙박스 모델을 생성했으며 지식 획득의 관점에서 본다면 연결주의 학습의 기술은 큰 약점이 있었다. 그러나 BP와 같은 효과적인 알고리즘 덕분에 많은 현실 응용에서 큰 힘을 발휘하기 시작했다. 연결주의 학습의 최대 한계는 시행착오이다. 학습 과정에서 많은 파라미터를 설정해야 하는데, 파라미터 설정에 대한 이론적인 가이드가 부족하고 대부분은 수동으로 파라미터 조정을 진행한다. 파라미터 조율상의 아주 사소한 실수 하나가 학습 결과에 지대한 영향을 미칠 수도 있다.
- 1990년대 중반, 통계 학습이 화려하게 등장하였다. 대표적인 기술로는 서포트 벡터 머신과 더 일반적으로는 커널 기법이 있다. 서포트 벡터 머신이 보편적으로 사람들에게 인정받고 난 후, 커널 트릭은 사람들에 의해 머신러닝에서 다양하게 사용되었다. 커널 함수 역시 머신러닝의 기본 내용 중 하나로 자리매김하게 된다. 
- 21세기 초에 연결주의 학습 열풍이 다시 불기 시작해 딥러닝에 대한 관심이 높아졌다. 딥러닝은 협의적 의미에서는 다층의 신경망을 뜻한다. 음성이나 이미지 등 복잡한 대상을 응용범위로 하는 연구에서 딥러닝 기술은 매우 뛰어난 성과를 거두었다. 이전의 머신러닝 기술은 응용 분야에서 좋은 성과를 내려면 사용자들에 대한 요구가 매우 높은 편이었다. 그러나 딥러닝 기술은 복잡도가 높다 할지라도 약간의 튜닝만 할 수 있다면 충분히 좋은 성능을 낼 수 있다는 장점이 있다. 따라서 딥러닝은 엄격한 이론 기초가 부족할지라도 머신러닝 응용의 문턱을 크게 낮추어 머신러닝 기술이 실전 엔지니어링에 응용되는 편의를 높였다. 