# Chapter 2. 모델 평가 및 선택

## 2.1. 경험 오차 및 과적합
- 오차율 : 전체 샘플 수와 잘못 분류한 샘플 수의 비율
- 정밀도 : 1 - 오차율
- 오차 : 학습기의 실제 예측 값과 샘플의 실제 값 사이의 차이
- 훈련 오차 : 학습기가 훈련 세트상에서 만들어낸 오차
- 일반화 오차 : 학습기가 새로운 샘플 위에서 만들어낸 오차
- 과적합 : 학습기가 훈련 데이터에서 학습을 과도하게 잘하여 훈련 데이터 중의 일정한 특성을 모든 데이터에서 내재된 일반 성질이라 오해하는 현상. 과적합이 발생하면 일반화 성능이 떨어지게 된다.
- 과소적합 : 학습기가 훈련 데이터의 일반화 성질을 제대로 배우지 못하는 현상
- 과적합은 학습능력이 너무 뛰어나 훈련 데이터들이 가진 일반적이지 않은 특성까지 학습하게 되며, 과소적합은 학습능력이 좋지 못해 발생한다.
- 과소적합은 훈련을 충분히 하여 해결할 수 있지만, 과적합은 피할 수 없다. 따라서 과적합을 완화하고 과적합이 일으키는 위험을 최소화하는 것에 만족해야 한다. 

## 2.2. 평가 방법
훈련 데이터로 학습된 학습기는 테스트 데이터를 활용하여 테스트 오차를 계산하고, 이를 실제 일반화 오차의 근삿값으로 가정한다. 이 때, 테스트 세트는 훈련 세트에서 사용한 것이 아니어야 하며, 훈련 과정에서 사용된 것이면 안된다. 데이터 세트를 훈련 세트와 테스트 세트로 나누는 방법은 다음과 같다.  
### 2.2.1. 홀드아웃
홀드아웃 방법은 데이터 세트를 겹치지 않는 임의의 두 집합으로 나눈다.  
훈련/테스트 세트를 나눌 때 되도록이면 데이터 분포가 같게 나눠야 한다. 그렇지 않으면 데이터 분포의 편향으로 인해 원치 않은 결과를 얻을 수 있다. 훈련/테스트 시트의 비율을 설정하는 것 외에도, 다양한 방식으로 데이터 세트에 대한 검증 세트 분류를 진행해야 한다. 검증 세트 기법의 예측값은 늘 불안정하여, 일반적으로 여러 번에 걸쳐 분류를 진행하고 검증하는 방법을 택한다.  
우리가 평가하고 싶은 것은 데이터 세트를 훈련시킨 모델의 성능이기 때문에, 검증 세트 기법을 사용한다면 일종의 딜레마에 빠질 수밖에 없다. 만약 훈련 세트에 대다수의 샘플이 들어 있다면 만들어진 모델은 데이터 세트 전체를 훈련시킨 것과 비슷하겠지만, 테스트 세트가 적은 탓에 안정적인 평가 결과를 얻지는 못한다. 반대로, 테스트 세트가 많은 샘플을 가져갈수록 훈련 세트와 데이터 세트의 차이는 벌어지고, 이는 데이터 세트 전체를 이용하여 훈련한 모델과 차이를 크게 만든다. 즉, 편과 결과의 신뢰도를 떨어뜨린다.  
어떻게 나눌 것인가에 대한 완벽한 해답은 없지만 일반적으로 60~80% 정도의 데이터를 훈련 세트로 사용하고 나머지를 테스트 세트로 분리하여 사용하는 것이 좋다.
### 2.2.2. 교차 검증

